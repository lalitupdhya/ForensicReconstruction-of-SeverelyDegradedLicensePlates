{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of training, validation and test data and pickling it to upload in google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "imgPath = 'E:\\\\license\\\\final_train' # train path in local machine\n",
    "\n",
    "for x in os.listdir(imgPath):\n",
    "    im = Image.open(os.path.join(imgPath, x))\n",
    "    imarray = np.array(im)\n",
    "    x_train.append(imarray)\n",
    "x_train = np.array(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85800, 50, 100, 3)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape # shape of train array with 85,800 images of shape 50,100,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = []\n",
    "imgpath = 'E:\\\\license\\\\final_val' # validation path in local machine\n",
    "\n",
    "for x in os.listdir(imgpath):\n",
    "    im = Image.open(os.path.join(imgpath, x))\n",
    "    imarray = np.array(im)\n",
    "    x_val.append(imarray)\n",
    "x_val = np.array(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920, 50, 100, 3)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape # shape of validation array with 7920 images of shape 50,100,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "imgpath = 'E:\\\\license\\\\final_test' # test path in local machine\n",
    "\n",
    "for x in os.listdir(imgpath):\n",
    "    im = Image.open(os.path.join(imgpath, x))\n",
    "    imarray = np.array(im)\n",
    "    #imarray = np.expand_dims(imarray, axis=0)\n",
    "    x_test.append(imarray)\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 50, 100, 3)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape # shape of test array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining path to create image labels\n",
    "\n",
    "imgPath_train = 'E:\\\\license\\\\final_train'\n",
    "imgPath_val = 'E:\\\\license\\\\final_val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting license number using image name for training images\n",
    "labels_train = []\n",
    "pattern = r'[A-Z0-9]{10}' #regex pattern\n",
    "\n",
    "for x in os.listdir(imgPath_train):\n",
    "    y = re.findall(pattern , x)\n",
    "    labels_train.append(list(y[0]))\n",
    "labels_train = np.array(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting license number using image name for validation images\n",
    "labels_val = []\n",
    "pattern = r'[A-Z0-9]{10}'\n",
    "\n",
    "for x in os.listdir(imgPath_val):\n",
    "    y = re.findall(pattern , x)\n",
    "    labels_val.append(list(y[0]))\n",
    "labels_val = np.array(labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = [char_labels.index(k) for k in labels_train[:,0]]\n",
    "c2 = [char_labels.index(k) for k in labels_train[:,1]]\n",
    "c3 = [num_labels.index(k) for k in labels_train[:,2]]\n",
    "c4 = [num_labels.index(k) for k in labels_train[:,3]]\n",
    "c5 = [char_labels.index(k) for k in labels_train[:,4]]\n",
    "c6 = [char_labels.index(k) for k in labels_train[:,5]]\n",
    "c7 = [num_labels.index(k) for k in labels_train[:,6]]\n",
    "c8 = [num_labels.index(k) for k in labels_train[:,7]]\n",
    "c9 = [num_labels.index(k) for k in labels_train[:,8]]\n",
    "c10 = [num_labels.index(k) for k in labels_train[:,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dictionary of training labels\n",
    "label_dict = {}\n",
    "\n",
    "label_dict['first_character'] = np.array(c1)\n",
    "label_dict['second_character'] = np.array(c2)\n",
    "label_dict['third_character'] = np.array(c3)\n",
    "label_dict['fourth_character'] = np.array(c4)\n",
    "label_dict['five_character'] = np.array(c5)\n",
    "label_dict['six_character'] = np.array(c6)\n",
    "label_dict['seven_character'] = np.array(c7)\n",
    "label_dict['eight_character'] = np.array(c8)\n",
    "label_dict['nine_character'] = np.array(c9)\n",
    "label_dict['ten_character'] = np.array(c10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = [char_labels.index(k) for k in labels_val[:,0]]\n",
    "v2 = [char_labels.index(k) for k in labels_val[:,1]]\n",
    "v3 = [num_labels.index(k) for k in labels_val[:,2]]\n",
    "v4 = [num_labels.index(k) for k in labels_val[:,3]]\n",
    "v5 = [char_labels.index(k) for k in labels_val[:,4]]\n",
    "v6 = [char_labels.index(k) for k in labels_val[:,5]]\n",
    "v7 = [num_labels.index(k) for k in labels_val[:,6]]\n",
    "v8 = [num_labels.index(k) for k in labels_val[:,7]]\n",
    "v9 = [num_labels.index(k) for k in labels_val[:,8]]\n",
    "v10 = [num_labels.index(k) for k in labels_val[:,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dictionary of validation labels\n",
    "label_val = {}\n",
    "\n",
    "label_val['first_character'] = np.array(v1)\n",
    "label_val['second_character'] = np.array(v2)\n",
    "label_val['third_character'] = np.array(v3)\n",
    "label_val['fourth_character'] = np.array(v4)\n",
    "label_val['five_character'] = np.array(v5)\n",
    "label_val['six_character'] = np.array(v6)\n",
    "label_val['seven_character'] = np.array(v7)\n",
    "label_val['eight_character'] = np.array(v8)\n",
    "label_val['nine_character'] = np.array(v9)\n",
    "label_val['ten_character'] = np.array(v10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library to pickle variables\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample showing to pickle variables\n",
    "# in the same way we pickled all the necessary variables and uploaded it to drive\n",
    "\n",
    "dbfile = open('E:\\\\license\\\\x_test.pkl', 'wb')\n",
    "pickle.dump(x_test, dbfile)\n",
    "dbfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### License Plate Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "deci = [7, 20] # SNR values\n",
    "resolutions = [45, 55] # width of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of origin\n",
    "imPath = 'E:\\\\license\\\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#destination\n",
    "destination = 'E:\\\\license\\\\final_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation variance using SNR value\n",
    "def cal(mean , db):\n",
    "    noise = db/20\n",
    "    x = 10**(noise)\n",
    "    return mean/x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmenting images\n",
    "\n",
    "for i in resolutions:\n",
    "    for j in deci:\n",
    "        for im in os.listdir(imPath):\n",
    "            \n",
    "            imgPath = os.path.join(imPath,im) # opening the image\n",
    "            img = Image.open(imgPath).resize((i,i//2)) # resing it to the widths 45 and 55\n",
    "            img = np.array(img) # converting it to numpy array\n",
    "            \n",
    "            # calculation variance for each of the three channels\n",
    "            sigma_1 = cal(np.mean(img[:, :, 0]) , j) \n",
    "            sigma_2 = cal(np.mean(img[:, :, 1]) , j)\n",
    "            sigma_3 = cal(np.mean(img[:, :, 2]) , j)\n",
    "            \n",
    "            # crating gaussian noise using variance of each of the three channels\n",
    "            gaussian_1 = np.random.normal(0, sigma_1, (i//2, i))\n",
    "            gaussian_2 = np.random.normal(0, sigma_2, (i//2, i))\n",
    "            gaussian_3 = np.random.normal(0, sigma_3, (i//2, i))\n",
    "            \n",
    "            # adding noise to the respective channels\n",
    "            noisy_image = np.zeros((i//2, i, 3))\n",
    "            \n",
    "            noisy_image[:, :, 0] = img[:, :, 0] + gaussian_1\n",
    "            noisy_image[:, :, 1] = img[:, :, 1] + gaussian_2\n",
    "            noisy_image[:, :, 2] = img[:, :, 2] + gaussian_3\n",
    "             \n",
    "            # normalising the image and saving it by resizing it to 100x50\n",
    "            cv2.normalize(noisy_image, noisy_image, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
    "            noisy_image = noisy_image.astype(np.uint8)\n",
    "            \n",
    "            noisy_image = Image.fromarray(noisy_image).resize((100,50))\n",
    "            noisy_image = np.array(noisy_image)\n",
    "            cv2.imwrite(os.path.join(destination , im[:-4]+'_'+str(i)+'_'+str(j)+'.png'), noisy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
